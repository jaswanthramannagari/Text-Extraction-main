{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a290b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import fnmatch\n",
    "import string\n",
    "import time\n",
    "\n",
    "path = 'E:\\\\mnt\\\\ramdisk\\\\max\\\\90kDICT32px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "052acf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.activations import relu, sigmoid, softmax\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b8a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#ignore warnings in the output\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f61260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3719711210494333270\n",
      "xla_global_id: -1\n",
      "]\n",
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Check all available devices if GPU is available\n",
    "print(device_lib.list_local_devices())\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16da95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = string.ascii_letters+string.digits\n",
    " \n",
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            print(char)\n",
    "        \n",
    "    return dig_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e855c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for training dataset\n",
    "training_img = []\n",
    "training_txt = []\n",
    "train_input_length = []\n",
    "train_label_length = []\n",
    "orig_txt = []\n",
    " \n",
    "#lists for validation dataset\n",
    "valid_img = []\n",
    "valid_txt = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_orig_txt = []\n",
    " \n",
    "max_label_len = 0\n",
    " \n",
    "i =1 \n",
    "flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a7dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(img):\n",
    "    b,g,r = cv2.split(img)\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd9b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for f_name in fnmatch.filter(filenames,'*.jpg'):\n",
    "        \n",
    "        img = cv2.imread(os.path.join(root, f_name))\n",
    "        #img = segmentation(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # convert each image of shape (32, 128, 1)\n",
    "        w, h = img.shape\n",
    "        if h > 128 or w > 32:\n",
    "            continue\n",
    "        if w < 32:\n",
    "            add_zeros = np.ones((32-w, h))*255\n",
    "            img = np.concatenate((img, add_zeros))\n",
    " \n",
    "        if h < 128:\n",
    "            add_zeros = np.ones((32, 128-h))*255\n",
    "            img = np.concatenate((img, add_zeros), axis=1)\n",
    "        \n",
    "        img = np.expand_dims(img , axis = 2)\n",
    "        \n",
    "        # Normalize each image\n",
    "        img = img/255.\n",
    "        \n",
    "        # get the text from the image\n",
    "        txt = f_name.split('_')[1]\n",
    "        \n",
    "        # compute maximum length of the text\n",
    "        if len(txt) > max_label_len:\n",
    "            max_label_len = len(txt)\n",
    "\n",
    "        #slit the dataset into 90% and 10%\n",
    "        if i%10 == 0:     \n",
    "            valid_orig_txt.append(txt)   \n",
    "            valid_label_length.append(len(txt))\n",
    "            valid_input_length.append(31)\n",
    "            valid_img.append(img)\n",
    "            valid_txt.append(encode_to_labels(txt))\n",
    "        else:\n",
    "            orig_txt.append(txt)   \n",
    "            train_label_length.append(len(txt))\n",
    "            train_input_length.append(31)\n",
    "            training_img.append(img)\n",
    "            training_txt.append(encode_to_labels(txt))\n",
    "        \n",
    "        # break the loop if total data is 150000\n",
    "        if i == 100000:\n",
    "            flag = 1\n",
    "            break\n",
    "        i+=1\n",
    "    if flag == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c57ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "len(training_img)\n",
    "print(training_img[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b49b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad each output label to maximum text length\n",
    " \n",
    "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
    "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d45ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input with shape of height=32 and width=128 \n",
    "inputs = Input(shape=(32,128,1))\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    " \n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
    " \n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    " \n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    " \n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "488adcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 128, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 128, 64)       640       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 32, 256)        295168    \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 32, 256)        590080    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 32, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 32, 512)        1180160   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 32, 512)       2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 32, 512)        2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 32, 512)       2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 32, 512)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 31, 512)        1049088   \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 31, 512)           0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 31, 256)          656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 31, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31, 63)            16191     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,619,711\n",
      "Trainable params: 6,617,663\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6259f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "#model to be used at training time\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3a9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    " \n",
    "filepath=\"best_model_v3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeee92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = np.array(training_img)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_label_length = np.array(train_label_length)\n",
    "\n",
    "valid_img = np.array(valid_img)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_label_length = np.array(valid_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be1e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 28.4085 \n",
      "Epoch 1: val_loss improved from inf to 27.11604, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 5213s 29s/step - loss: 28.4085 - val_loss: 27.1160\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 23.9714 \n",
      "Epoch 2: val_loss did not improve from 27.11604\n",
      "180/180 [==============================] - 5144s 29s/step - loss: 23.9714 - val_loss: 28.6492\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 13.9309 \n",
      "Epoch 3: val_loss improved from 27.11604 to 24.95727, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 5060s 28s/step - loss: 13.9309 - val_loss: 24.9573\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 6.4876 \n",
      "Epoch 4: val_loss improved from 24.95727 to 8.57182, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 5043s 28s/step - loss: 6.4876 - val_loss: 8.5718\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 4.9317 \n",
      "Epoch 5: val_loss improved from 8.57182 to 4.96972, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 5046s 28s/step - loss: 4.9317 - val_loss: 4.9697\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 4.2274 \n",
      "Epoch 6: val_loss improved from 4.96972 to 4.63272, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 5631s 31s/step - loss: 4.2274 - val_loss: 4.6327\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 3.7083 \n",
      "Epoch 7: val_loss did not improve from 4.63272\n",
      "180/180 [==============================] - 5666s 31s/step - loss: 3.7083 - val_loss: 4.7381\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 3.3618 \n",
      "Epoch 8: val_loss improved from 4.63272 to 4.39564, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 4933s 27s/step - loss: 3.3618 - val_loss: 4.3956\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 3.0438 \n",
      "Epoch 9: val_loss improved from 4.39564 to 4.30536, saving model to best_model_v3.hdf5\n",
      "180/180 [==============================] - 4843s 27s/step - loss: 3.0438 - val_loss: 4.3054\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - ETA: 0s - loss: 2.7800 \n",
      "Epoch 10: val_loss did not improve from 4.30536\n",
      "180/180 [==============================] - 4627s 26s/step - loss: 2.7800 - val_loss: 4.3388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18af2665cd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "epochs = 10\n",
    "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f04b1c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text =   Expend\n",
      "predicted text = Expend\n",
      "\n",
      "original_text =   RAKE\n",
      "predicted text = BAKE\n",
      "\n",
      "original_text =   IMAM\n",
      "predicted text = IMaM\n",
      "\n",
      "original_text =   kraft\n",
      "predicted text = kraft\n",
      "\n",
      "original_text =   deceleration\n",
      "predicted text = deceleratinn\n",
      "\n",
      "original_text =   FOXHUNTING\n",
      "predicted text = FOXHUNTING\n",
      "\n",
      "original_text =   Renaud\n",
      "predicted text = Renaud\n",
      "\n",
      "original_text =   Trenchant\n",
      "predicted text = Trenchant\n",
      "\n",
      "original_text =   HOD\n",
      "predicted text = HOD\n",
      "\n",
      "original_text =   sculpt\n",
      "predicted text = sculpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the saved best model weights\n",
    "act_model.load_weights('best_model_v3.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "prediction = act_model.predict(valid_img[:10])\n",
    " \n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    " \n",
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", valid_orig_txt[i])\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3907a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img):\n",
    "    act_model.load_weights('best_model_v2.hdf5')\n",
    "\n",
    "    # predict outputs on validation images\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img = cv2.resize(img, (128,32))\n",
    "    img = np.expand_dims(img , axis = 2)\n",
    "    img = img.reshape(1,32,128,1)\n",
    "    prediction = act_model.predict(img)\n",
    "\n",
    "    # use CTC decoder\n",
    "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                             greedy=True)[0][0])\n",
    "\n",
    "    for p in out[0]:  \n",
    "            if int(p) != -1:\n",
    "                print(char_list[int(p)], end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a237246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('image.png')\n",
    "cv2.imwrite('image.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d2b4054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOWERART"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "test(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db356937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dd3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d381e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
